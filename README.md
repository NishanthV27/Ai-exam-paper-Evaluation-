# ğŸ“˜ AI Powered Exam Paper Evaluation System

## ğŸ“Œ Project Overview

The **AI Powered Exam Paper Evaluation System** is a web-based application that automatically evaluates student answer sheets using Artificial Intelligence and Machine Learning techniques.

The system allows users (teacher/admin) to upload:
- Question paper (PDF or Image)
- Student answer sheet (PDF or Image)

Using **OCR (Optical Character Recognition)**, the system extracts text from the uploaded files.  
An AI model generates correct answers for each question and compares them with student answers using **semantic similarity**.  
Based on the similarity score, marks and grades are calculated automatically.

This project reduces manual correction time and improves accuracy in exam evaluation.

---

## ğŸ¯ Objectives

- Automate the exam paper evaluation process  
- Reduce manual effort of teachers  
- Improve accuracy and speed of correction  
- Apply AI and Machine Learning in education  
- Generate and store results digitally  

---

## âš™ï¸ Features

- Upload question paper and student answer sheet (PDF/Image)  
- Extract text using OCR (Tesseract & PyPDF2)  
- Generate correct answers using AI (GPT4All)  
- Compare answers using Sentence Transformer (ML model)  
- Automatic marks and grade calculation  
- Store results in SQLite database  
- View results in dashboard  
- Download results as PDF  
- Simple web interface using Flask  

---

## ğŸ› ï¸ Technologies Used

### ğŸ”¹ Backend
- Python  
- Flask  

### ğŸ”¹ Frontend
- HTML  
- CSS  

### ğŸ”¹ AI / Machine Learning
- SentenceTransformer (all-mpnet-base-v2)  
- GPT4All  

### ğŸ”¹ OCR & File Handling
- Pytesseract  
- PyPDF2  
- PIL (Pillow)  

### ğŸ”¹ Database
- SQLite  

### ğŸ”¹ Other Libraries
- FPDF  
- Regex  
- OS  

---

## ğŸ”„ System Workflow

1. User uploads:
   - Question paper  
   - Student answer sheet  
2. System extracts text using OCR  
3. AI generates correct answers for each question  
4. Student answers are compared with correct answers  
5. Similarity score is converted into marks  
6. Grade is calculated  
7. Result is saved in database  
8. User can view and download result  

---

## ğŸ§© Project Structure

AI-Exam-Evaluation-System/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ exam.db
â”œâ”€â”€ uploads/
â”œâ”€â”€ templates/
â”‚ â”œâ”€â”€ upload_questions.html
â”‚ â”œâ”€â”€ result.html
â”‚ â””â”€â”€ dashboard.html
â”œâ”€â”€ static/
â”‚ â””â”€â”€ style.css
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt


---

## â–¶ï¸ How to Run the Project

### Step 1: Clone the Repository
```bash
git clone https://github.com/your-username/ai-exam-evaluation-system.git
cd ai-exam-evaluation-system
Step 2: Create Virtual Environment (Optional)
python -m venv venv
venv\Scripts\activate
Step 3: Install Required Libraries
pip install -r requirements.txt
Step 4: Run the Application
python app.py
Step 5: Open in Browser
http://127.0.0.1:5000/
ğŸ“‹ Requirements
Create a requirements.txt file with:

flask
pytesseract
pillow
PyPDF2
sentence-transformers
gpt4all
fpdf
sqlite3
ğŸ“Š Grading System
Marks (%)	Grade
90 â€“ 100	A+
75 â€“ 89	A
60 â€“ 74	B
50 â€“ 59	C
Below 50	Fail
ğŸš€ Future Enhancements
Add user authentication (login system)

Support for multiple subjects

Improve accuracy using fine-tuned AI models

Add charts and analytics in dashboard

Deploy on cloud (AWS / Render / Heroku)

Mobile responsive UI

ğŸ‘¨â€ğŸ’» Author
Nishanth
B.Tech AI & ML Student
AI and Full Stack Developer

